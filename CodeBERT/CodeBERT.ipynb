{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8b9021",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f3af74",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR=\"Results/CodeBERT_Original_wduplicates_CVE_Fixes_5050_lora_batch_16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f92c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL=true\n",
      "env: WANDB_NOTEBOOK_NAME=DiverseVul_CodeBERT\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "%env WANDB_LOG_MODEL=true\n",
    "%env WANDB_NOTEBOOK_NAME=DiverseVul_CodeBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99811f76",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7916f206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiago\\anaconda3\\envs\\Mamba_Env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk, Dataset\n",
    "\n",
    "def load_dataset() -> Dataset:\n",
    "    \"\"\" Load dataset. \"\"\"\n",
    "    dataset = load_from_disk(\"../datasets/cve_fixes_original_balanced_5050.hf/\")\n",
    "    dataset = dataset.shuffle(seed=42)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf41149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 6456\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1845\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 923\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74fc15aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f8c3553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9224/9224 [00:03<00:00, 2662.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 512\n",
      "Average source length: 374.1322636600174\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"], dataset[\"validation\"]]).map(\n",
    "    lambda x: tokenizer(x[\"text\"], truncation=True), batched=True, remove_columns=['text', 'label']\n",
    ")\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# Calculate the average input length\n",
    "average_source_length = sum(len(x) for x in tokenized_inputs[\"input_ids\"]) / len(tokenized_inputs[\"input_ids\"])\n",
    "print(f\"Average source length: {average_source_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af84d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6456/6456 [00:02<00:00, 2415.21 examples/s]\n",
      "Map: 100%|██████████| 1845/1845 [00:00<00:00, 2241.68 examples/s]\n",
      "Map: 100%|██████████| 923/923 [00:00<00:00, 2317.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from calendar import IllegalWeekdayError\n",
    "import re\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=max_source_length)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5c2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9759c",
   "metadata": {},
   "source": [
    "# Configure LoRA (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63b89236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(inference_mode=False, r=8,\n",
    "lora_alpha=32,\n",
    "lora_dropout=0.05,\n",
    "task_type=TaskType.SEQ_CLS)\n",
    "\n",
    "from peft import get_peft_model\n",
    "model_peft = get_peft_model(model, lora_config)\n",
    "model_peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b7760a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tiago\\anaconda3\\envs\\Mamba_Env\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### STARTING TRAINING ###\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tiago\\OneDrive - Instituto Superior de Engenharia do Porto\\Documents\\GECAD\\DiverseVul LLMs Analysis\\DiverseVul Code\\CodeBERT\\wandb\\run-20240408_015600-b33ns7ou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/1180939/huggingface/runs/b33ns7ou' target=\"_blank\">CodeBERT_Original_wduplicates_CVE_Fixes_5050_lora_batch_16</a></strong> to <a href='https://wandb.ai/1180939/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/1180939/huggingface' target=\"_blank\">https://wandb.ai/1180939/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/1180939/huggingface/runs/b33ns7ou' target=\"_blank\">https://wandb.ai/1180939/huggingface/runs/b33ns7ou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 200/4380 [02:11<46:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6985, 'grad_norm': 1.5461689233779907, 'learning_rate': 2e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  5%|▍         | 200/4380 [02:31<46:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6960322856903076, 'eval_f1': 0.015779092702169626, 'eval_runtime': 20.094, 'eval_samples_per_second': 49.816, 'eval_steps_per_second': 6.271, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 400/4380 [04:47<45:13,  1.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6975, 'grad_norm': 2.003352165222168, 'learning_rate': 1.904306220095694e-05, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  9%|▉         | 400/4380 [05:07<45:13,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6970914006233215, 'eval_f1': 0.0, 'eval_runtime': 20.2919, 'eval_samples_per_second': 49.33, 'eval_steps_per_second': 6.209, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 600/4380 [07:28<43:11,  1.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6987, 'grad_norm': 2.1406302452087402, 'learning_rate': 1.8086124401913876e-05, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 14%|█▎        | 600/4380 [07:49<43:11,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6954200863838196, 'eval_f1': 0.0, 'eval_runtime': 21.1836, 'eval_samples_per_second': 47.253, 'eval_steps_per_second': 5.948, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 800/4380 [10:10<42:02,  1.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.697, 'grad_norm': 1.3740450143814087, 'learning_rate': 1.7129186602870815e-05, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 18%|█▊        | 800/4380 [10:31<42:02,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6974743604660034, 'eval_f1': 0.0, 'eval_runtime': 20.8418, 'eval_samples_per_second': 48.029, 'eval_steps_per_second': 6.046, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1000/4380 [12:53<39:37,  1.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6964, 'grad_norm': 2.0569632053375244, 'learning_rate': 1.6172248803827754e-05, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 23%|██▎       | 1000/4380 [13:14<39:37,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6956376433372498, 'eval_f1': 0.06946983546617916, 'eval_runtime': 20.9486, 'eval_samples_per_second': 47.784, 'eval_steps_per_second': 6.015, 'epoch': 2.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1200/4380 [15:38<37:29,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.695, 'grad_norm': 1.6130834817886353, 'learning_rate': 1.5215311004784689e-05, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 27%|██▋       | 1200/4380 [15:59<37:29,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6954227685928345, 'eval_f1': 0.16293929712460065, 'eval_runtime': 20.7496, 'eval_samples_per_second': 48.242, 'eval_steps_per_second': 6.072, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1400/4380 [18:24<35:41,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6951, 'grad_norm': 1.4497530460357666, 'learning_rate': 1.4258373205741626e-05, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 32%|███▏      | 1400/4380 [18:45<35:41,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934942603111267, 'eval_f1': 0.5345794392523364, 'eval_runtime': 21.118, 'eval_samples_per_second': 47.4, 'eval_steps_per_second': 5.966, 'epoch': 3.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1600/4380 [21:08<32:21,  1.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6949, 'grad_norm': 2.022117853164673, 'learning_rate': 1.3301435406698567e-05, 'epoch': 3.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 37%|███▋      | 1600/4380 [21:30<32:21,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7053442001342773, 'eval_f1': 0.0, 'eval_runtime': 21.0652, 'eval_samples_per_second': 47.519, 'eval_steps_per_second': 5.981, 'epoch': 3.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1800/4380 [23:53<30:13,  1.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6923, 'grad_norm': 4.9014363288879395, 'learning_rate': 1.2344497607655504e-05, 'epoch': 4.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 41%|████      | 1800/4380 [24:15<30:13,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.695906400680542, 'eval_f1': 0.17981072555205047, 'eval_runtime': 21.7379, 'eval_samples_per_second': 46.049, 'eval_steps_per_second': 5.796, 'epoch': 4.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2000/4380 [26:39<27:50,  1.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6938, 'grad_norm': 1.7185057401657104, 'learning_rate': 1.1387559808612441e-05, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 46%|████▌     | 2000/4380 [27:00<27:50,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6937527656555176, 'eval_f1': 0.5351043643263758, 'eval_runtime': 21.0019, 'eval_samples_per_second': 47.662, 'eval_steps_per_second': 5.999, 'epoch': 4.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2200/4380 [29:24<25:48,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6934, 'grad_norm': 1.8224973678588867, 'learning_rate': 1.0430622009569378e-05, 'epoch': 5.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 50%|█████     | 2200/4380 [29:46<25:48,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6973007321357727, 'eval_f1': 0.09490333919156414, 'eval_runtime': 21.3314, 'eval_samples_per_second': 46.926, 'eval_steps_per_second': 5.907, 'epoch': 5.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2400/4380 [32:12<23:46,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6919, 'grad_norm': 3.247354745864868, 'learning_rate': 9.473684210526315e-06, 'epoch': 5.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 55%|█████▍    | 2400/4380 [32:33<23:46,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941039562225342, 'eval_f1': 0.4161712247324614, 'eval_runtime': 21.3322, 'eval_samples_per_second': 46.924, 'eval_steps_per_second': 5.907, 'epoch': 5.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2600/4380 [34:59<21:49,  1.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6907, 'grad_norm': 1.4741106033325195, 'learning_rate': 8.516746411483254e-06, 'epoch': 5.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 59%|█████▉    | 2600/4380 [35:20<21:49,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6933002471923828, 'eval_f1': 0.4905263157894737, 'eval_runtime': 21.3299, 'eval_samples_per_second': 46.929, 'eval_steps_per_second': 5.907, 'epoch': 5.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2800/4380 [37:46<18:22,  1.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.689, 'grad_norm': 2.3312647342681885, 'learning_rate': 7.5598086124401915e-06, 'epoch': 6.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 64%|██████▍   | 2800/4380 [38:07<18:22,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930064558982849, 'eval_f1': 0.5825242718446602, 'eval_runtime': 21.1596, 'eval_samples_per_second': 47.307, 'eval_steps_per_second': 5.955, 'epoch': 6.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3000/4380 [40:33<16:10,  1.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6893, 'grad_norm': 2.5146334171295166, 'learning_rate': 6.6028708133971295e-06, 'epoch': 6.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 68%|██████▊   | 3000/4380 [40:54<16:10,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6941763162612915, 'eval_f1': 0.6014913007456504, 'eval_runtime': 21.0181, 'eval_samples_per_second': 47.626, 'eval_steps_per_second': 5.995, 'epoch': 6.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3200/4380 [43:20<14:12,  1.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6873, 'grad_norm': 1.3902982473373413, 'learning_rate': 5.645933014354067e-06, 'epoch': 7.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 73%|███████▎  | 3200/4380 [43:41<14:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934567093849182, 'eval_f1': 0.5782073813708261, 'eval_runtime': 20.9433, 'eval_samples_per_second': 47.796, 'eval_steps_per_second': 6.016, 'epoch': 7.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3400/4380 [46:07<11:43,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6878, 'grad_norm': 2.267875909805298, 'learning_rate': 4.6889952153110055e-06, 'epoch': 7.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 78%|███████▊  | 3400/4380 [46:28<11:43,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6945304274559021, 'eval_f1': 0.3324538258575198, 'eval_runtime': 20.8307, 'eval_samples_per_second': 48.054, 'eval_steps_per_second': 6.049, 'epoch': 7.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 3600/4380 [48:52<09:15,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6887, 'grad_norm': 1.8189021348953247, 'learning_rate': 3.732057416267943e-06, 'epoch': 8.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 82%|████████▏ | 3600/4380 [49:13<09:15,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6938614845275879, 'eval_f1': 0.38976857490864797, 'eval_runtime': 21.5387, 'eval_samples_per_second': 46.474, 'eval_steps_per_second': 5.85, 'epoch': 8.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 3800/4380 [51:39<06:51,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6858, 'grad_norm': 3.1877036094665527, 'learning_rate': 2.7751196172248807e-06, 'epoch': 8.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 87%|████████▋ | 3800/4380 [52:00<06:51,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6954439878463745, 'eval_f1': 0.3150684931506849, 'eval_runtime': 21.0841, 'eval_samples_per_second': 47.476, 'eval_steps_per_second': 5.976, 'epoch': 8.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 4000/4380 [54:26<04:36,  1.37it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6909, 'grad_norm': 1.688993215560913, 'learning_rate': 1.8181818181818183e-06, 'epoch': 9.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 91%|█████████▏| 4000/4380 [54:48<04:36,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6927552223205566, 'eval_f1': 0.5190525231719877, 'eval_runtime': 21.6728, 'eval_samples_per_second': 46.187, 'eval_steps_per_second': 5.814, 'epoch': 9.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4200/4380 [57:14<02:09,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6852, 'grad_norm': 3.4430410861968994, 'learning_rate': 8.612440191387561e-07, 'epoch': 9.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 96%|█████████▌| 4200/4380 [57:36<02:09,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6927598714828491, 'eval_f1': 0.526100307062436, 'eval_runtime': 21.7156, 'eval_samples_per_second': 46.096, 'eval_steps_per_second': 5.802, 'epoch': 9.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4380/4380 [59:47<00:00,  1.52it/s]c:\\Users\\tiago\\anaconda3\\envs\\Mamba_Env\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 3593.6707, 'train_samples_per_second': 19.487, 'train_steps_per_second': 1.219, 'train_loss': 0.6921575798835928, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4380/4380 [59:48<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import evaluate\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./CodeBERT_Original_wduplicates_CVE_Fixes_5050_lora_batch_16\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    # weight_decay=1e-3,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps=200,\n",
    "    save_steps=200,\n",
    "    warmup_steps=200,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_dir=RESULTS_DIR + \"/logs\",  # Replace with your desired logging directory\n",
    "    report_to=\"wandb\",\n",
    "    run_name = RESULTS_DIR.split('/')[1],\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Define a Trainer instance with the prepared datasets\n",
    "trainer = Trainer(\n",
    "    model=model_peft,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator  \n",
    ")\n",
    "\n",
    "print(\"### STARTING TRAINING ###\")\n",
    "train_output = trainer.train()\n",
    "\n",
    "# trainer.save_model(RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1368dfbb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a17c33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:44<00:00,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.65      0.58      1001\n",
      "           1       0.53      0.40      0.46      1001\n",
      "\n",
      "    accuracy                           0.52      2002\n",
      "   macro avg       0.53      0.52      0.52      2002\n",
      "weighted avg       0.53      0.52      0.52      2002\n",
      "\n",
      "0.5239760239760239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def evaluate(model) -> None:\n",
    "    \"\"\"Evaluate the model on the test dataset.\"\"\"\n",
    "    predictions_list, labels_list = [], []\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    test_results = model.predict(tokenized_datasets[\"test\"])\n",
    "    predictions_list = test_results.predictions.argmax(axis=1)\n",
    "\n",
    "    labels_list = tokenized_datasets[\"test\"][\"label\"]\n",
    "\n",
    "    report = classification_report(labels_list, predictions_list)\n",
    "    accuracy = accuracy_score(labels_list, predictions_list)\n",
    "    print(report)\n",
    "    print(accuracy)\n",
    "\n",
    "evaluate(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0afc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e38bdacfe1d6e2b7e20a64d2eef782d7715e4314dc541be72f500d3c69b94a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
